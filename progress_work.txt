Ход выполнения работы и описание структуры проекта
Работа над проектом «Интеллектуальная система классификации новостных статей по тематике» была организована в строгой последовательности этапов, каждый из которых включал как технические действия, так и разработку соответствующих программных компонентов. Ниже приводится полное описание хода работы с детализацией созданных файлов и их функционального назначения.

1. Подготовка вычислительного окружения
Проект начинался с создания изолированной среды разработки. Было сформировано виртуальное окружение Python с помощью команды python -m venv .venv, что позволило отделить зависимости проекта от глобальной установки Python. В окружение были установлены ключевые библиотеки через файл requirements.txt, включая torch с поддержкой CUDA (для ускорения на GPU NVIDIA GeForce RTX 4050), transformers, datasets, scikit-learn, pandas, matplotlib и другие. Для обеспечения корректной работы системы кэширования Hugging Face и совместимости с Windows была выполнена активация Developer Mode в настройках Windows, что позволило использовать символические ссылки и повысило эффективность кэширования моделей.

2. Сбор и подготовка данных
В качестве источника данных был использован открытый датасет Lenta.Ru News Dataset, содержащий более 800 000 новостных статей. Поскольку в нём отсутствовало достаточное количество статей по теме «Наука и технологии», было решено ограничиться четырьмя основными категориями: «Политика», «Экономика», «Спорт» и «Культура».

Для подготовки данных был разработан скрипт src/prepare_data.py, который выполнял следующие действия:

Загружал исходный файл data/raw/lenta-ru-news.csv.
Переразмечал рубрики (например, объединял «Россия» и «Мир» в «Политику»).
Удалял пустые и слишком короткие тексты.
Балансировал выборку (по 5000 статей на класс).
Разделял данные на обучающую (14 000 статей), валидационную (3 000) и тестовую (3 000) подвыборки с сохранением пропорций классов.
Сохранял результат в папку data/processed/ в виде трёх CSV-файлов: train.csv, val.csv, test.csv.
Этот этап обеспечил наличие чистого, сбалансированного и структурированного датасета, пригодного для обучения модели.

3. Обучение модели
Для решения задачи классификации была выбрана предобученная языковая модель cointegrated/rubert-tiny2 — компактная версия RuBERT, оптимизированная для устройств с ограниченной видеопамятью (включая RTX 4050 с 6 ГБ VRAM).

Обучение осуществлялось с помощью скрипта src/train.py, который:

Загружал подготовленные данные из data/processed/.
Кодировал текстовые категории в числовые метки.
Инициализировал модель и токенизатор.
Настроил параметры обучения: MAX_LENGTH = 256, BATCH_SIZE = 8, EPOCHS = 3.
Выполнял дообучение модели в течение трёх эпох.
Из-за особенностей совместимости библиотеки transformers в Windows, вместо автоматической валидации через параметр evaluation_strategy использовалась ручная валидация после каждой эпохи с помощью вызова trainer.evaluate().
Сохранял финальную модель в папку models/rubert_news_classifier/.
Папка модели содержит все необходимые файлы: веса (pytorch_model.bin), конфигурацию (config.json), токенизатор (tokenizer.json) и другие метаданные, что делает её полностью автономной и готовой к развёртыванию.

4. Оценка качества и визуализация результатов
Для объективной оценки качества системы был реализован скрипт src/evaluate.py, который:

Загружал обученную модель из models/rubert_news_classifier/.
Загружал тестовую выборку (data/processed/test.csv), не участвовавшую в обучении.
Выполнял предсказания пакетами.
Рассчитывал метрики: precision, recall, F1-score по каждому классу и общую accuracy.
Генерировал три графика и сохранял их в папку results/:
Столбчатая диаграмма (metrics_by_class.png) — сравнение метрик по категориям.
Матрица ошибок (confusion_matrix.png) — визуализация типичных ошибок (например, путаница между «Политикой» и «Экономикой»).
График динамики обучения (training_dynamics.png) — изменение loss и точности по эпохам.
Выводил в консоль полный classification_report.
Результаты показали высокое качество: accuracy = 95%, macro F1 = 95%, при этом лучшие результаты достигнуты для категории «Спорт» (F1 = 0.99), а наименьшие — для «Политики» (F1 = 0.92), что объясняется семантической близостью с экономической тематикой.

5. Реализация инференса
Для практического применения системы был создан скрипт src/predict.py, позволяющий:

Передавать на вход произвольный текст (через аргумент командной строки).
Получать предсказанную тематическую категорию.
При запуске без аргументов — демонстрировать примеры работы.
Скрипт использует ту же обученную модель, работает на GPU (если доступен) и готов к интеграции в веб-сервис, API или десктопное приложение.

6. Общая структура проекта
Все компоненты проекта организованы в следующую структуру:

ТУТ ДОЛЖЕН БЫТЬ СКРИНШОТ ТОГО КАК ВЫГЛЯДИТ СТРУКТУРА ПРОЕКТА


Такая организация обеспечивает полную воспроизводимость, модульность и готовность к дальнейшему развитию.

Заключение
В результате выполнения работы была создана законченная, эффективная и академически строгая система автоматической классификации новостных статей на русском языке. Все этапы — от сбора данных до финального инференса — были реализованы с учётом ограничений оборудования, особенностей операционной системы и требований к качеству машинного обучения. Проект демонстрирует высокие результаты (95% точности) и полностью соответствует поставленной цели.